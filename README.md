# Code Analysis & Context Engineering MCP - Python Edition

A sophisticated Model Context Protocol (MCP) server that provides deep codebase understanding for Python projects, with a focus on data analysis frameworks and scientific computing.

## ğŸ¯ Overview

This MCP server is specifically designed for Python projects, especially those using data analysis and scientific computing libraries. It provides architectural analysis, pattern detection, dependency mapping, test coverage analysis, and AI-optimized context generation.

## âœ¨ Features

- **ğŸ—ï¸ Architecture Analysis**: Comprehensive architectural overview with module relationships, class hierarchies, and data flow patterns
- **ğŸ” Pattern Detection**: Identify data analysis patterns, best practices, and antipatterns
- **ğŸ“Š Dependency Mapping**: Visualize module dependencies, detect circular dependencies, and analyze coupling
- **ğŸ§ª Coverage Analysis**: Find untested code with actionable test suggestions based on complexity
- **âœ… Convention Validation**: Validate adherence to PEP 8 and project-specific coding conventions
- **ğŸ¤– Context Generation**: Build optimal AI context packs respecting token limits and maximizing relevance

## ğŸ Supported Frameworks & Libraries

### Data Analysis & Scientific Computing
- âœ… **Pandas** - DataFrame operations, data transformations, aggregations
- âœ… **NumPy** - Array manipulations, mathematical operations, broadcasting
- âœ… **Scikit-learn** - ML pipelines, model training, feature engineering
- âœ… **Matplotlib/Seaborn** - Visualization patterns, plot types
- âœ… **Jupyter Notebooks** - Notebook structure, cell analysis

### Web Frameworks
- âœ… **FastAPI** - Async endpoints, dependency injection, Pydantic models
- âœ… **Django** - Models, views, ORM patterns, middleware
- âœ… **Flask** - Routes, blueprints, decorators

### Testing Frameworks
- âœ… **Pytest** - Test discovery, fixtures, parametrization
- âœ… **Unittest** - Test cases, mocking, assertions

## ğŸ“¦ Installation

### Prerequisites

- Python 3.10 or higher
- pip or poetry for package management

### Install from source

```bash
git clone https://github.com/andreahaku/code-analysis-context-python-mcp.git
cd code-analysis-context-python-mcp
pip install -e .
```

### Development installation

```bash
pip install -e ".[dev]"
```

## ğŸš€ Usage

### As an MCP Server

Add to your MCP client configuration (e.g., Claude Desktop):

```json
{
  "mcpServers": {
    "code-analysis-python": {
      "command": "python",
      "args": ["-m", "src.server"]
    }
  }
}
```

Or using the installed script:

```json
{
  "mcpServers": {
    "code-analysis-python": {
      "command": "code-analysis-python-mcp"
    }
  }
}
```

## ğŸ› ï¸ Available Tools

### 1. `arch` - Architecture Analysis

Analyze Python project architecture and structure.

```json
{
  "path": "/path/to/project",
  "depth": "d",
  "types": ["mod", "class", "func", "api"],
  "diagrams": true,
  "metrics": true,
  "details": true,
  "minCx": 10,
  "maxFiles": 50
}
```

**Parameters:**
- `path`: Project root directory
- `depth`: Analysis depth - "o" (overview), "d" (detailed), "x" (deep)
- `types`: Analysis types - mod, class, func, api, model, view, notebook, pipeline, dataflow
- `diagrams`: Generate Mermaid diagrams
- `metrics`: Include code metrics
- `details`: Per-file detailed metrics
- `minCx`: Minimum complexity threshold for filtering
- `maxFiles`: Maximum number of files in detailed output
- `memSuggest`: Generate memory suggestions for llm-memory MCP
- `fw`: Force framework detection - pandas, numpy, sklearn, fastapi, django, flask, jupyter

**Detects:**
- Module structure and organization
- Class hierarchies and inheritance patterns
- Function definitions and decorators
- API endpoints (FastAPI/Django/Flask)
- Data models and Pydantic schemas
- Jupyter notebook structure
- Data processing pipelines

### 2. `deps` - Dependency Analysis

Analyze module dependencies and imports.

```json
{
  "path": "/path/to/project",
  "circular": true,
  "metrics": true,
  "diagram": true,
  "focus": "src/models",
  "depth": 3
}
```

**Parameters:**
- `path`: Project root directory
- `circular`: Detect circular dependencies
- `metrics`: Calculate coupling/cohesion metrics
- `diagram`: Generate Mermaid dependency graph
- `focus`: Focus on specific module
- `depth`: Maximum dependency depth to traverse
- `external`: Include site-packages dependencies

**Features:**
- Import graph construction
- Circular dependency detection with cycle paths
- Coupling and cohesion metrics
- Dependency hotspots (hubs and bottlenecks)
- Module classification (utility, service, model, etc.)

### 3. `patterns` - Pattern Detection

Detect data analysis and coding patterns.

```json
{
  "path": "/path/to/project",
  "types": ["dataframe", "array", "pipeline", "model", "viz"],
  "custom": true,
  "best": true,
  "suggest": true
}
```

**Parameters:**
- `path`: Project root directory
- `types`: Pattern types to detect
  - `dataframe`: Pandas DataFrame operations
  - `array`: NumPy array manipulations
  - `pipeline`: Scikit-learn pipelines
  - `model`: ML model training patterns
  - `viz`: Matplotlib/Seaborn visualizations
  - `api`: FastAPI/Django/Flask endpoints
  - `orm`: Django ORM patterns
  - `async`: Async/await patterns
  - `decorator`: Custom decorators
  - `context`: Context managers
- `custom`: Detect custom patterns
- `best`: Compare with best practices
- `suggest`: Generate improvement suggestions

**Detected Patterns:**
- **Pandas**: DataFrame chaining, groupby operations, merge strategies
- **NumPy**: Broadcasting, vectorization, array creation patterns
- **Scikit-learn**: Pipelines, transformers, model training
- **Visualization**: Plot types, figure management, style patterns
- **API**: Endpoint patterns, request/response models, middleware
- **Async**: Async functions, coroutines, event loops
- **Testing**: Fixtures, mocking, parametrization

### 4. `coverage` - Test Coverage Analysis

Analyze test coverage and generate test suggestions.

```json
{
  "path": "/path/to/project",
  "report": ".coverage",
  "fw": "pytest",
  "threshold": {
    "lines": 80,
    "functions": 80,
    "branches": 75
  },
  "priority": "high",
  "tests": true,
  "cx": true
}
```

**Parameters:**
- `path`: Project root directory
- `report`: Coverage report path (.coverage, coverage.xml)
- `fw`: Test framework - pytest, unittest, nose
- `threshold`: Coverage thresholds
- `priority`: Filter priority - crit, high, med, low, all
- `tests`: Generate test scaffolds
- `cx`: Analyze complexity for prioritization

**Features:**
- Parse coverage.py reports
- Identify untested modules and functions
- Complexity-based prioritization
- Test scaffold generation (pytest/unittest)
- Framework-specific test patterns

### 5. `conventions` - Convention Validation

Validate PEP 8 and coding conventions.

```json
{
  "path": "/path/to/project",
  "auto": true,
  "severity": "warn",
  "rules": {
    "naming": {
      "functions": "snake_case",
      "classes": "PascalCase"
    }
  }
}
```

**Parameters:**
- `path`: Project root directory
- `auto`: Auto-detect project conventions
- `severity`: Minimum severity - err, warn, info
- `rules`: Custom convention rules

**Checks:**
- PEP 8 compliance
- Naming conventions (snake_case, PascalCase, UPPER_CASE)
- Import ordering and grouping
- Docstring presence
- Type hint usage
- Line length and formatting

### 6. `context` - Context Pack Generation

Generate AI-optimized context packs.

```json
{
  "task": "Add data preprocessing pipeline with pandas",
  "path": "/path/to/project",
  "tokens": 50000,
  "include": ["files", "arch", "patterns"],
  "focus": ["src/preprocessing", "src/models"],
  "format": "md",
  "lineNums": true,
  "strategy": "rel"
}
```

**Parameters:**
- `task`: Task description (required)
- `path`: Project root directory
- `tokens`: Token budget (default: 50000)
- `include`: Content types - files, deps, tests, types, arch, conv, notebooks
- `focus`: Priority files/directories
- `history`: Include git history
- `format`: Output format - md, json, xml
- `lineNums`: Include line numbers
- `strategy`: Optimization strategy - rel (relevance), wide (breadth), deep (depth)

**Features:**
- Task-based file relevance scoring
- Token budget management
- Multiple output formats
- Architectural context inclusion
- Dependency traversal

## ğŸ“ Configuration

Create a `.code-analysis.json` file in your project root:

```json
{
  "project": {
    "name": "MyDataProject",
    "type": "pandas"
  },
  "analysis": {
    "includeGlobs": ["src/**/*.py", "notebooks/**/*.ipynb"],
    "excludeGlobs": ["**/test_*.py", "**/__pycache__/**", "**/venv/**"]
  },
  "conventions": {
    "naming": {
      "functions": "snake_case",
      "classes": "PascalCase",
      "constants": "UPPER_SNAKE_CASE"
    },
    "imports": {
      "order": ["stdlib", "third_party", "local"],
      "grouping": true
    }
  },
  "coverage": {
    "threshold": {
      "lines": 80,
      "functions": 80,
      "branches": 75
    }
  }
}
```

## ğŸ”§ Development

### Project Structure

```
code-analysis-context-python-mcp/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ server.py              # MCP server entry point
â”‚   â”œâ”€â”€ tools/                 # Tool implementations
â”‚   â”‚   â”œâ”€â”€ architecture_analyzer.py
â”‚   â”‚   â”œâ”€â”€ pattern_detector.py
â”‚   â”‚   â”œâ”€â”€ dependency_mapper.py
â”‚   â”‚   â”œâ”€â”€ coverage_analyzer.py
â”‚   â”‚   â”œâ”€â”€ convention_validator.py
â”‚   â”‚   â””â”€â”€ context_pack_generator.py
â”‚   â”œâ”€â”€ analyzers/             # Framework-specific analyzers
â”‚   â”œâ”€â”€ utils/                 # Utilities (AST, complexity, etc.)
â”‚   â””â”€â”€ types/                 # Type definitions
â”œâ”€â”€ tests/                     # Test suite
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
```

### Running Tests

```bash
pytest
pytest --cov=src --cov-report=html
```

### Code Quality

```bash
# Format code
black src tests
isort src tests

# Lint
flake8 src tests

# Type checking
mypy src
```

## ğŸ¯ Implementation Status

### âœ… All Features Complete!

**Core Tools (100% Complete)**
- âœ… **Architecture Analyzer** - AST parsing, complexity metrics, framework detection, Mermaid diagrams
- âœ… **Pattern Detector** - DataFrame/array/ML patterns, async/decorators, antipatterns, best practices
- âœ… **Dependency Mapper** - Import graphs, circular detection, coupling metrics, hotspots
- âœ… **Coverage Analyzer** - Coverage.py integration, test scaffolds, complexity-based prioritization
- âœ… **Convention Validator** - PEP 8 checking, naming conventions, docstrings, auto-detection
- âœ… **Context Pack Generator** - Task-based relevance, token budgets, multiple formats, AI optimization

**Utilities (100% Complete)**
- âœ… AST Parser - Classes, functions, imports, complexity
- âœ… Complexity Analyzer - Radon integration, maintainability index
- âœ… File Scanner - Glob patterns, intelligent filtering
- âœ… Framework Detector - 14+ frameworks, pattern matching
- âœ… Diagram Generator - Mermaid architecture & dependency graphs

**Features**
- âœ… Circular dependency detection with cycle paths
- âœ… LLM memory integration for persistent context
- âœ… Test scaffold generation (pytest/unittest)
- âœ… Multi-format output (JSON, Markdown, XML)
- âœ… Token budget management for AI tools
- âœ… Complexity-based prioritization
- âœ… Mermaid diagram generation

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

MIT

## ğŸ‘¨â€ğŸ’» Author

Andrea Salvatore (@andreahaku) with Claude (Anthropic)

## ğŸ”— Related Projects

- [llm-memory-mcp](https://github.com/andreahaku/llm_memory_mcp) - Persistent memory for LLM tools
- [code-analysis-context-mcp](https://github.com/andreahaku/code-analysis-context-mcp) - TypeScript/JavaScript version

## ğŸ§ª Testing

Test all tools on this project itself:

```bash
python3 test_tools.py
```

This will run all 6 tools and display:
- Project architecture and complexity metrics
- Pattern detection (async, decorators, context managers)
- Dependency graph and coupling metrics
- Coverage gaps with priorities
- Convention violations and consistency scores
- AI context pack generation

## ğŸ“Š Example Output

Running the tools on this project shows:
- **18 modules**, **9 classes**, **61 functions**, **3,787 lines of code**
- **38 patterns detected** (17 async functions, 21 decorators)
- **0 circular dependencies** - clean architecture!
- **0% test coverage** - needs tests (demonstrates coverage tool)
- **High complexity** (avg 36.8) - identifies refactoring targets
- **100% naming consistency** - follows PEP 8

---

**Status**: âœ… **Production Ready** - All 6 tools fully implemented and tested

**Python Version**: 3.10+

**Lines of Code**: 3,787
**Test Coverage**: Functional (integration tests via test_tools.py)
**Code Quality**: High consistency, follows PEP 8
